{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcxv-C5tA8Di"
      },
      "outputs": [],
      "source": [
        "# Ques: What is hypothesis testing in statistics?\n",
        "# Ans:\n",
        "# Hypothesis testing in statistics is a method used to decide whether there is enough evidence in a sample of data to support a specific claim (hypothesis) about a population. It involves:\n",
        "# Null hypothesis (H₀) – the default assumption (e.g., no effect or no difference).\n",
        "# Alternative hypothesis (H₁) – what you want to test for.\n",
        "# Test statistic – calculated from sample data.\n",
        "# P-value – probability of observing the result if H₀ is true.\n",
        "# Conclusion – if the p-value is less than a chosen significance level (e.g., 0.05), reject H₀."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "# Ans:\n",
        "# The null hypothesis (H₀) is a statement that there is no effect or no difference—it represents the default or status quo.\n",
        "# The alternative hypothesis (H₁ or Ha) is a statement that there is an effect or a difference—it’s what the researcher aims to prove.\n",
        "# Difference:\n",
        "# H₀ assumes nothing has changed.\n",
        "# H₁ suggests a change or effect exists.\n",
        "# In hypothesis testing, we test data against H₀ and may reject it in favor of H₁ if evidence is strong."
      ],
      "metadata": {
        "id": "C-FIuHIzBZXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the significance level in hypothesis testing, and why is it important?\n",
        "# Ans:\n",
        "# The significance level (α) is the threshold for deciding whether to reject the null hypothesis, commonly set at 0.05 (5%).\n",
        "# Importance:\n",
        "# It defines the maximum risk of making a Type I error—rejecting a true null hypothesis. A lower α means stricter criteria for rejecting H₀, ensuring more confidence in the results."
      ],
      "metadata": {
        "id": "NGftINTIBhv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What does a P-value represent in hypothesis testing?\n",
        "# Ans:\n",
        "# A p-value is the probability of getting the observed results, or more extreme ones, if the null hypothesis (H₀) is true.\n",
        "# In short:\n",
        "# A low p-value (≤ α) suggests strong evidence against H₀, so we reject it.\n",
        "# A high p-value (> α) suggests weak evidence, so we fail to reject H₀."
      ],
      "metadata": {
        "id": "t3aQ4CaTBnWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: How do you interpret the P-value in hypothesis testing?\n",
        "# Ans:\n",
        "# To interpret the p-value in hypothesis testing:\n",
        "# If p-value ≤ significance level (α): Reject the null hypothesis (H₀) – there's enough evidence to support the alternative hypothesis.\n",
        "# If p-value > α: Fail to reject H₀ – not enough evidence to support a change or effect."
      ],
      "metadata": {
        "id": "pgFZkJJiBt8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "# Ans:\n",
        "# In hypothesis testing:\n",
        "# Type 1 Error (False Positive): Rejecting the null hypothesis (H₀) when it is actually true.\n",
        "# Type 2 Error (False Negative): Failing to reject H₀ when the alternative hypothesis (H₁) is actually true."
      ],
      "metadata": {
        "id": "6ThXuVNbB0O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques; What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
        "# Ans:\n",
        "# One-tailed test checks for an effect in one specific direction (e.g., greater than or less than).\n",
        "# Two-tailed test checks for an effect in both directions (e.g., not equal to)."
      ],
      "metadata": {
        "id": "egfy-swNCLUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the Z-test, and when is it used in hypothesis testing\n",
        "# Ans:\n",
        "# A Z-test is a statistical test used to determine if there is a significant difference between sample and population means when the population standard deviation is known and the sample size is large (n ≥ 30)."
      ],
      "metadata": {
        "id": "jLAmhxbvCQc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "# Ans:\n",
        "# The Z-score shows how many standard deviations the sample mean is from the population mean. It helps determine how likely the result is under the null hypothesis."
      ],
      "metadata": {
        "id": "yNNLz7QHCV1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the T-distribution, and when should it be used instead of the normal distribution\n",
        "# Ans:\n",
        "# The T-distribution is a probability distribution used in place of the normal distribution when the sample size is small (n < 30) and the population standard deviation is unknown."
      ],
      "metadata": {
        "id": "lgJ7olWzCcMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the difference between a Z-test and a T-test\n",
        "# Ans:\n",
        "# Z-test:\n",
        "# Used when population standard deviation is known\n",
        "# Sample size is large (n ≥ 30)\n",
        "# Based on normal distribution\n",
        "\n",
        "# T-test:\n",
        "# Used when population standard deviation is unknown\n",
        "# Sample size is small (n < 30)\n",
        "# Based on t-distribution"
      ],
      "metadata": {
        "id": "o1ksiKqzClV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the T-test, and how is it used in hypothesis testing\n",
        "# Ans:\n",
        "# A T-test is a statistical test used to compare sample means when the population standard deviation is unknown and the sample size is small.\n",
        "# In hypothesis testing:\n",
        "# It helps determine if the difference between the sample mean and population mean (or between two sample means) is statistically significant."
      ],
      "metadata": {
        "id": "cZqlYYJLC_ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the relationship between Z-test and T-test in hypothesis testing\n",
        "# Ans:\n",
        "# The Z-test and T-test both compare means to test hypotheses, but:\n",
        "# The Z-test is used when the population standard deviation is known and the sample size is large.\n",
        "# The T-test is used when the population standard deviation is unknown and/or the sample size is small."
      ],
      "metadata": {
        "id": "yxVJiyBrDGaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:What is a confidence interval, and how is it used to interpret statistical results\n",
        "# Ans:\n",
        "# A confidence interval is a range of values, calculated from sample data, that likely contains the true population parameter with a certain confidence level (e.g., 95%).\n",
        "# It shows the uncertainty around an estimate and helps interpret the precision of results."
      ],
      "metadata": {
        "id": "7c5-40C-DLFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the margin of error, and how does it affect the confidence interval?\n",
        "# Ams:\n",
        "# The margin of error is the maximum expected difference between the sample estimate and the true population value.\n",
        "# It affects the confidence interval by:\n",
        "# Widening or narrowing the interval.\n",
        "# A larger margin of error means a wider confidence interval (less precise).\n",
        "# A smaller margin of error means a narrower interval (more precise)."
      ],
      "metadata": {
        "id": "DNx_SwiuDN3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: How is Bayes' Theorem used in statistics, and what is its significance\n",
        "# Ans:\n",
        "# Bayes’ Theorem in statistics is used to update the probability of a hypothesis based on new evidence or data.\n",
        "# It combines:\n",
        "# Prior probability (initial belief)\n",
        "# Likelihood (how probable the new data is given the hypothesis)\n",
        "# To calculate the posterior probability (updated belief after seeing the data).\n",
        "# Significance:\n",
        "# It allows for dynamic learning and decision-making by revising probabilities as more information becomes available."
      ],
      "metadata": {
        "id": "Y_FYtYIODsV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the Chi-square distribution, and when is it used\n",
        "# Ans:\n",
        "# The Chi-square distribution is a probability distribution used for tests involving categorical data and variances.\n",
        "# Used in:\n",
        "# Testing goodness of fit\n",
        "# Testing independence in contingency tables\n",
        "# Testing variance of a normally distributed population"
      ],
      "metadata": {
        "id": "zvlNiooFD12T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the Chi-square goodness of fit test, and how is it applied?\n",
        "# Ans:\n",
        "# The Chi-square goodness of fit test checks if observed categorical data matches an expected distribution.\n",
        "# How it’s applied:\n",
        "# Compare observed frequencies to expected frequencies.\n",
        "# Calculate Chi-square statistic.\n",
        "# Determine if differences are due to chance or indicate a poor fit"
      ],
      "metadata": {
        "id": "aoyU1Kz5D8rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the F-distribution, and when is it used in hypothesis testing\n",
        "# Ans:\n",
        "# The F-distribution is a probability distribution used to compare variances of two populations.\n",
        "# Used in hypothesis testing for:\n",
        "# ANOVA (Analysis of Variance) to test if group means are equal\n",
        "# Comparing two sample variances"
      ],
      "metadata": {
        "id": "85-EMxIFECh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is an ANOVA test, and what are its assumptions\n",
        "# Ans:\n",
        "# ANOVA (Analysis of Variance) tests whether there are significant differences between the means of three or more groups.\n",
        "# Assumptions:\n",
        "# Independence of observations\n",
        "# Normality – data in each group is normally distributed\n",
        "# Homogeneity of variances – equal variances across groups"
      ],
      "metadata": {
        "id": "rcnCJw9FEHi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What are the different types of ANOVA tests\n",
        "# Ans:\n",
        "# The main types of ANOVA tests are:\n",
        "# One-way ANOVA: Tests differences between means of one independent variable with multiple groups.\n",
        "# Two-way ANOVA: Tests effects of two independent variables and their interaction on the dependent variable.\n",
        "# Repeated Measures ANOVA: Tests means when the same subjects are measured under different conditions or times."
      ],
      "metadata": {
        "id": "aI86hYnHENs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: What is the F-test, and how does it relate to hypothesis testing\n",
        "# Ans:\n",
        "# The F-test compares the variances of two or more groups to see if they are significantly different.\n",
        "# In hypothesis testing:\n",
        "# It’s used to test if group means are equal (e.g., in ANOVA) by analyzing variance ratios."
      ],
      "metadata": {
        "id": "i3CuInBQETS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICAL"
      ],
      "metadata": {
        "id": "fbXbGlxSEZrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  Write a Python script to visualize the distribution of errors (residuals) for a multiple linear regression model using Seaborn's \"diamonds\" dataset\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "\n",
        "# Drop rows with missing values (if any)\n",
        "diamonds = diamonds.dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = diamonds.drop(columns='price')\n",
        "y = diamonds['price']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include='category').columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a pipeline with linear regression\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate residuals\n",
        "y_pred = model.predict(X_test)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Plot residual distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(residuals, bins=50, kde=True, color='purple')\n",
        "plt.title('Distribution of Residuals')\n",
        "plt.xlabel('Residual')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mgEBvx_wEVha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script to calculate and print Mean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE) for a linear regression model\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Load the dataset\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "diamonds = diamonds.dropna()\n",
        "\n",
        "# Features and target\n",
        "X = diamonds.drop(columns='price')\n",
        "y = diamonds['price']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include='category').columns.tolist()\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create a pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n"
      ],
      "metadata": {
        "id": "1LvJY-rr1HSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script to check if the assumptions of linear regression are met. Use a scatter plot to check linearity, residuals plot for homoscedasticity, and correlation matrix for multicollinearity\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "diamonds = sns.load_dataset('diamonds').dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = diamonds.drop(columns='price')\n",
        "y = diamonds['price']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include='category').columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# === 1. Linearity ===\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.3)\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Linearity Check: Actual vs Predicted\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# === 2. Homoscedasticity ===\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.scatterplot(x=y_pred, y=residuals, alpha=0.3)\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel(\"Predicted Price\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Homoscedasticity Check: Residuals vs Predicted\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# === 3. Multicollinearity ===\n",
        "plt.figure(figsize=(10, 8))\n",
        "corr_matrix = diamonds[numerical_cols].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n",
        "plt.title(\"Multicollinearity Check: Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eDTpFSbH1NLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that creates a machine learning pipeline with feature scaling and evaluates the performance of different regression models\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Load dataset\n",
        "diamonds = sns.load_dataset('diamonds').dropna()\n",
        "\n",
        "# Define features and target\n",
        "X = diamonds.drop(columns='price')\n",
        "y = diamonds['price']\n",
        "\n",
        "# Categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include='category').columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
        "    ('num', StandardScaler(), numerical_cols)\n",
        "])\n",
        "\n",
        "# Regression models to evaluate\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Ridge Regression\": Ridge(),\n",
        "    \"Lasso Regression\": Lasso(),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "for name, regressor in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', regressor)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"-----------------------------\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n"
      ],
      "metadata": {
        "id": "U2ZeheqI1T4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Implement a simple linear regression model on a dataset and print the model's coefficients, intercept, and R-squared score.\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Load and prepare the data\n",
        "df = sns.load_dataset('diamonds').dropna()\n",
        "X = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "# Identify column types\n",
        "categorical_cols = X.select_dtypes(include='category').columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define regression models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'R² Score': r2,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse\n",
        "    })\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results).sort_values(by='R² Score', ascending=False)\n",
        "\n",
        "# Print results\n",
        "print(results_df)\n",
        "\n",
        "# Optional: Plot RMSE comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='RMSE', y='Model', data=results_df, palette='mako')\n",
        "plt.title('Model Comparison by RMSE')\n",
        "plt.xlabel('Root Mean Squared Error')\n",
        "plt.ylabel('Regression Model')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PkNUFj3Z1ch4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that analyzes the relationship between total bill and tip in the 'tips' dataset using simple linear regression and visualizes the results\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Define X and y\n",
        "X = tips[['total_bill']]\n",
        "y = tips['tip']\n",
        "\n",
        "# Fit simple linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict tips\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f\"Intercept: {model.intercept_:.2f}\")\n",
        "print(f\"Slope (Coefficient): {model.coef_[0]:.2f}\")\n",
        "\n",
        "# Visualize the data and regression line\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='total_bill', y='tip', data=tips, label='Data points')\n",
        "plt.plot(tips['total_bill'], y_pred, color='red', label='Regression Line')\n",
        "plt.title('Linear Regression: Tip vs Total Bill')\n",
        "plt.xlabel('Total Bill')\n",
        "plt.ylabel('Tip')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "M-UbxAsN1i38"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that fits a linear regression model to a synthetic dataset with one feature. Use the model to predict new values and plot the data points along with the regression line\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=15, random_state=42)\n",
        "\n",
        "# Fit a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Print model parameters\n",
        "print(f\"Intercept: {model.intercept_:.2f}\")\n",
        "print(f\"Coefficient: {model.coef_[0]:.2f}\")\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression line')\n",
        "plt.title('Linear Regression on Synthetic Data')\n",
        "plt.xlabel('Feature (X)')\n",
        "plt.ylabel('Target (y)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mRsUe38w1mdO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that pickles a trained linear regression model and saves it to a file.\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=1)\n",
        "\n",
        "# Train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Display model parameters\n",
        "print(f\"Model trained: Intercept = {model.intercept_:.2f}, Coefficient = {model.coef_[0]:.2f}\")\n",
        "\n",
        "# Pickle (serialize) the model\n",
        "with open('linear_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Model saved as 'linear_model.pkl'\")\n"
      ],
      "metadata": {
        "id": "mgZzvGUg1pwc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  Write a Python script that fits a polynomial regression model (degree 2) to a dataset and plots the regression curve\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Generate synthetic non-linear data\n",
        "np.random.seed(42)\n",
        "X = np.sort(2 * np.random.rand(100, 1), axis=0)\n",
        "y = 4 + 3 * X[:, 0] + 2 * X[:, 0]**2 + np.random.randn(100) * 2  # Quadratic relationship with noise\n",
        "\n",
        "# Reshape y\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Create polynomial regression pipeline (degree 2)\n",
        "degree = 2\n",
        "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict for plotting\n",
        "X_plot = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "y_pred = model.predict(X_plot)\n",
        "\n",
        "# Plot the data and the polynomial regression curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X_plot, y_pred, color='red', linewidth=2, label=f'Degree {degree} Polynomial Fit')\n",
        "plt.title(f'Polynomial Regression (Degree {degree})')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VddlkURa1thJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Generate synthetic data for simple linear regression (use random values for X and y) and fit a linear regression model to the data. Print the model's coefficient and intercept\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate synthetic data\n",
        "X = 2 * np.random.rand(100, 1)  # 100 random values between 0 and 2\n",
        "y = 5 + 3 * X + np.random.randn(100, 1)  # Linear relation with noise\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the model parameters\n",
        "print(f\"Coefficient (slope): {model.coef_[0][0]:.2f}\")\n",
        "print(f\"Intercept: {model.intercept_[0]:.2f}\")\n"
      ],
      "metadata": {
        "id": "YFRFOEhi1xHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  Write a Python script that fits polynomial regression models of different degrees to a synthetic dataset and compares their performance\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = np.sort(2 * np.random.rand(100, 1), axis=0)\n",
        "y = 4 + 3 * X[:, 0] - 2 * X[:, 0]**2 + X[:, 0]**3 + np.random.randn(100) * 2  # Nonlinear relationship\n",
        "\n",
        "# Reshape y\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Degrees to test\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "X_plot = np.linspace(0, 2, 100).reshape(-1, 1)\n",
        "\n",
        "for degree in degrees:\n",
        "    # Create polynomial regression pipeline\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X)\n",
        "    r2 = r2_score(y, y_pred)\n",
        "\n",
        "    # Plot regression curve\n",
        "    y_plot = model.predict(X_plot)\n",
        "    plt.plot(X_plot, y_plot, label=f'Degree {degree} (R²={r2:.3f})')\n",
        "\n",
        "# Plot original data\n",
        "plt.scatter(X, y, color='black', alpha=0.5, label='Data points')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression Model Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rFehEtBH2Mss"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that fits a simple linear regression model with two features and prints the model's coefficients, intercept, and R-squared score\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate synthetic data\n",
        "X = 2 * np.random.rand(100, 2)  # 100 samples, 2 features\n",
        "# Create target with a linear relationship plus noise\n",
        "y = 3 + 2 * X[:, 0] + 4 * X[:, 1] + np.random.randn(100)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R² score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print model details\n",
        "print(f\"Intercept: {model.intercept_:.2f}\")\n",
        "print(f\"Coefficients: {model.coef_}\")\n",
        "print(f\"R-squared score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "qw5RQcnV2RBV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that generates synthetic data, fits a linear regression model, and visualizes the regression line along with the data points\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(100, 1)        # Feature values between 0 and 2\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)  # Linear relation with noise\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Print model parameters\n",
        "print(f\"Intercept: {model.intercept_[0]:.2f}\")\n",
        "print(f\"Coefficient: {model.coef_[0][0]:.2f}\")\n",
        "\n",
        "# Visualize data points and regression line\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression Fit')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C45EPhil2Tto"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that uses the Variance Inflation Factor (VIF) to check for multicollinearity in a dataset with multiple features\n",
        "# Ans:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Example: Generate synthetic dataset with multicollinearity\n",
        "np.random.seed(0)\n",
        "X1 = np.random.rand(100)\n",
        "X2 = 2 * X1 + np.random.normal(0, 0.1, 100)  # Highly correlated with X1\n",
        "X3 = np.random.rand(100)\n",
        "X4 = 0.5 * X3 + np.random.normal(0, 0.1, 100)  # Moderately correlated with X3\n",
        "\n",
        "df = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3, 'X4': X4})\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['Feature'] = df.columns\n",
        "vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "4V7vUYPa2Yr-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques  Write a Python script that generates synthetic data for a polynomial relationship (degree 4), fits a polynomial regression model, and plots the regression curve\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data\n",
        "X = np.sort(np.random.rand(100, 1) * 2 - 1, axis=0)  # X values between -1 and 1\n",
        "\n",
        "# True polynomial relationship (degree 4) with some noise\n",
        "y = 1 - 2*X[:, 0] + 3*X[:, 0]**2 - 4*X[:, 0]**3 + 5*X[:, 0]**4 + np.random.randn(100) * 0.5\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Create polynomial regression pipeline with degree 4\n",
        "degree = 4\n",
        "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict on a smooth range for plotting\n",
        "X_plot = np.linspace(-1, 1, 200).reshape(-1, 1)\n",
        "y_plot = model.predict(X_plot)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', alpha=0.6, label='Data points')\n",
        "plt.plot(X_plot, y_plot, color='red', linewidth=2, label=f'Polynomial Degree {degree}')\n",
        "plt.title('Polynomial Regression (Degree 4)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6AukZ8qo2dER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that creates a machine learning pipeline with data standardization and a multiple linear regression model, and prints the R-squared score\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data with 3 features\n",
        "np.random.seed(0)\n",
        "X = 5 * np.random.rand(200, 3)\n",
        "y = 3 + 2 * X[:, 0] + 4 * X[:, 1] - 3 * X[:, 2] + np.random.randn(200)  # Linear relation with noise\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline: StandardScaler + LinearRegression\n",
        "pipeline = make_pipeline(StandardScaler(), LinearRegression())\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared score on test set: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "1k0rI3sB2_LC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that performs polynomial regression (degree 3) on a synthetic dataset and plots the regression curve\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.sort(np.random.rand(100, 1) * 2 - 1, axis=0)  # Values between -1 and 1\n",
        "y = 1 + 2*X[:, 0] - 3*X[:, 0]**2 + 4*X[:, 0]**3 + np.random.randn(100) * 0.5\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Create polynomial regression model (degree 3)\n",
        "degree = 3\n",
        "model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict values for smooth curve\n",
        "X_plot = np.linspace(-1, 1, 200).reshape(-1, 1)\n",
        "y_plot = model.predict(X_plot)\n",
        "\n",
        "# Plot data points and regression curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X, y, color='blue', alpha=0.6, label='Data points')\n",
        "plt.plot(X_plot, y_plot, color='red', linewidth=2, label=f'Polynomial Degree {degree}')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Polynomial Regression (Degree 3)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X3Jyixtg3DJo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that performs multiple linear regression on a synthetic dataset with 5 features. Print the R-squared score and model coefficients\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate synthetic data with 5 features\n",
        "X = np.random.rand(200, 5)\n",
        "# Define target with a linear combination of features plus noise\n",
        "true_coefs = np.array([3, -1.5, 2, 0, 4.5])\n",
        "y = X @ true_coefs + np.random.randn(200) * 0.5  # y = X*coefs + noise\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"R-squared score: {r2:.4f}\")\n",
        "print(\"Model coefficients:\", model.coef_)\n",
        "print(f\"Intercept: {model.intercept_:.4f}\")\n"
      ],
      "metadata": {
        "id": "DqouljLG3Fy8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that generates synthetic data for linear regression, fits a model, and visualizes the data points along with the regression line\n",
        "# Ans:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(100, 1)            # Feature values between 0 and 2\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)   # Linear relation with noise\n",
        "\n",
        "# Fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict values\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Print model parameters\n",
        "print(f\"Intercept: {model.intercept_[0]:.2f}\")\n",
        "print(f\"Coefficient: {model.coef_[0][0]:.2f}\")\n",
        "\n",
        "# Plot data points and regression line\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred, color='red', linewidth=2, label='Regression line')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression Fit')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hhda0UlL3Kyu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Create a synthetic dataset with 3 features and perform multiple linear regression. Print the model's Rsquared score and coefficients\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate synthetic data with 3 features\n",
        "X = np.random.rand(150, 3)\n",
        "\n",
        "# Define target variable as a linear combination of features + noise\n",
        "true_coefs = np.array([4, -2, 3])\n",
        "y = X @ true_coefs + np.random.randn(150) * 0.5  # y = 4*X1 - 2*X2 + 3*X3 + noise\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print model coefficients and R-squared\n",
        "print(f\"R-squared score: {r2:.4f}\")\n",
        "print(f\"Model coefficients: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_:.4f}\")\n"
      ],
      "metadata": {
        "id": "EVXo-0t83PRr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that demonstrates how to serialize and deserialize machine learning models using joblib instead of pickling.\n",
        "# Ans:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# Generate synthetic regression data\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
        "\n",
        "# Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Train a simple linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model to a file using joblib\n",
        "joblib_file = \"linear_regression_model.joblib\"\n",
        "joblib.dump(model, joblib_file)\n",
        "print(f\"Model saved to {joblib_file}\")\n",
        "\n",
        "# Load the model back from the file\n",
        "loaded_model = joblib.load(joblib_file)\n",
        "print(\"Model loaded from file.\")\n",
        "\n",
        "# Use loaded model to make predictions\n",
        "predictions = loaded_model.predict(X_test)\n",
        "print(f\"Predictions on test data: {predictions[:5]}\")\n"
      ],
      "metadata": {
        "id": "8M2j4SCq3RW4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  Write a Python script to perform linear regression with categorical features using one-hot encoding. Use the Seaborn 'tips' dataset\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the 'tips' dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Select features and target\n",
        "# We'll predict 'tip' using 'total_bill' (numerical) and 'sex', 'smoker', 'day', 'time' (categorical)\n",
        "X = tips[['total_bill', 'sex', 'smoker', 'day', 'time']]\n",
        "y = tips['tip']\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R-squared score: {r2:.4f}\")\n",
        "print(\"Model coefficients:\")\n",
        "for feature, coef in zip(X_encoded.columns, model.coef_):\n",
        "    print(f\"  {feature}: {coef:.4f}\")\n"
      ],
      "metadata": {
        "id": "Pk5hsYnr3Vrk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques:  Write a Python script to perform linear regression with categorical features using one-hot encoding. Use the Seaborn 'tips' dataset\n",
        "# Ans:\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the 'tips' dataset\n",
        "tips = sns.load_dataset('tips')\n",
        "\n",
        "# Select features and target\n",
        "X = tips[['total_bill', 'sex', 'smoker', 'day', 'time']]  # predictors\n",
        "y = tips['tip']  # target\n",
        "\n",
        "# One-hot encode categorical features\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"R-squared score: {r2:.4f}\")\n",
        "print(\"Coefficients:\")\n",
        "for feature, coef in zip(X_encoded.columns, model.coef_):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n"
      ],
      "metadata": {
        "id": "f3uSNbNL3anS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that uses cross-validation to evaluate a Linear Regression model on a synthetic dataset\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Generate synthetic regression data\n",
        "X, y = make_regression(n_samples=200, n_features=3, noise=10, random_state=42)\n",
        "\n",
        "# Initialize linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Perform 5-fold cross-validation with R-squared as scoring metric\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "\n",
        "# Print the results\n",
        "print(f\"R-squared scores for each fold: {cv_scores}\")\n",
        "print(f\"Average R-squared score: {np.mean(cv_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "qfI8GwFJ3eZn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques: Write a Python script that compares polynomial regression models of different degrees and prints the Rsquared score for each\n",
        "# Ans:\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X = np.sort(np.random.rand(100, 1) * 2 - 1, axis=0)  # X in [-1,1]\n",
        "y = 1 - 2*X[:, 0] + 3*X[:, 0]**2 - 4*X[:, 0]**3 + np.random.randn(100) * 0.5\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Degree | R-squared\")\n",
        "print(\"------------------\")\n",
        "\n",
        "# Fit and evaluate polynomial regression models with degrees 1 to 5\n",
        "for degree in range(1, 6):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{degree:^6} | {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "A4he3pqD3h81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}